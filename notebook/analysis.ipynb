{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUxQLesOhQo8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "74848e35"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n",
        "from numpy.core.fromnumeric import squeeze\n",
        "from imblearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.decomposition import PCA\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB, CategoricalNB\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.under_sampling import NearMiss\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import SCORERS\n",
        "from sklearn.model_selection import cross_validate\n",
        "import seaborn as sns\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2, f_regression \n",
        "from sklearn.feature_selection import f_classif, mutual_info_classif, f_regression, mutual_info_regression\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from imblearn.over_sampling import BorderlineSMOTE, ADASYN\n",
        "from imblearn.combine import SMOTEENN\n",
        "from sklearn.metrics import make_scorer\n",
        "from imblearn.metrics import macro_averaged_mean_absolute_error\n",
        "from sklearn.metrics import balanced_accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "c7c301d5"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "qypwUtY0MHi8"
      },
      "outputs": [],
      "source": [
        "#importo il dataset\n",
        "df = pd.read_csv('data_football_ratings.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "rewgt-bpGv_a"
      },
      "outputs": [],
      "source": [
        "#differenziare tra centrocampisti centrali (MF) e i centrocampisti difensivi (DMF) e i centrocampisti offensivi (AMF)\n",
        "df.loc[df.pos_role == 'DMC', 'pos'] = 'DMF'\n",
        "df.loc[df.pos_role == 'DMR', 'pos'] = 'DMF'\n",
        "df.loc[df.pos_role == 'DML', 'pos'] = 'DMF'\n",
        "\n",
        "df.loc[df.pos_role == 'AMC', 'pos'] = 'AMF'\n",
        "df.loc[df.pos_role == 'AMR', 'pos'] = 'AMF'\n",
        "df.loc[df.pos_role == 'AML', 'pos'] = 'AMF'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "KsTERqOjr6-H"
      },
      "outputs": [],
      "source": [
        "#in pos, al posto di Sub metto \"nan\", in questo modo poi quando si fa la media, la funzione mode() non considera \"Sub\" come un ruolo, ma scarta direttamente i nan, non li considera\n",
        "df.loc[df.pos == 'Sub','pos'] = np.nan\n",
        "\n",
        "#per ogni calciatore calcolo la moda delle loro posizioni, in modo da assegnare la posizione alle istanze che non ce l'hanno, che hanno 'Sub' invece che la loro vera posizione\n",
        "#creo un altro dataframe in cui abbiamo calciatore e la loro posizione, calcolata condiserando la loro posizione che è occorsa più volte nel dataset (moda)\n",
        "df_reduced = df.groupby('player').pos.agg(pd.Series.mode).to_frame('moda_pos').reset_index()\n",
        "\n",
        "#elimino tutte le istanze per cui non si è potuto stabilire una moda (erano tutti Sub/nan) o una moda univoca (c'erano 1 MF e 1 DF)\n",
        "df_reduced.drop([9,12,21,22,37,39,44,51,52,56,67,68,78,90,92,101,119,125,129,135,142,149,164,170,176,177,179,180,182,189,207,217,227,235,239,245,257,258,259,266,272,294,301,310,313,321,323,338,351,371,384,394,402,403,414,415,423,438,444,445,453,457,467,473,475,480,489,491,501,504,515,516,531,538,550,578,583,584,602,603,604,616,621,628,630,636,643,645,664,678,684,695,702,713,719,734,738,745,757,761,762,766,785,790,791,795,809,812,825,836,844,850,854,871,879,891,897,898,899,911,916,919,923,928,929,933,937,942,945,982,994,999,1017,1040,1043,1048,1058,1060,1070,1082,1084,1091,1093,1095,1099,1106,1114,1117,1122,1130,1138,1140,1141,1144,1163,1165,1175,1191,1194,1198,1203,1203,1208,1210,1213,1214,1222,1229,1246,1253,1259,1265,1267,1281,1287,1288,1292,1293,1312,1328,1330,1346,1348,1368,1373,1375,1414,1415,1418,1421,1422,1430,1431,1433,1437,1440,1444,1446,1459,1464,1478,1495,1526,1531,1533,1535,1537,1576,1588,1603,1617], inplace= True)\n",
        "\n",
        "df_reduced.loc[df_reduced.player =='Diafra Sakho','moda_pos'] = 'FW'\n",
        "df_reduced.loc[df_reduced.player =='Julien Ngoy','moda_pos'] = 'FW'\n",
        "df_reduced.loc[df_reduced.player =='Carlos Sanchez','moda_pos'] = 'MF'\n",
        "df_reduced.loc[df_reduced.player =='Christoph Janker','moda_pos'] = 'DF'\n",
        "df_reduced.loc[df_reduced.player =='Riechedly Bazoer','moda_pos'] = 'MF'\n",
        "df_reduced.loc[df_reduced.player =='Sebastian Maier','moda_pos'] = 'MF'\n",
        "\n",
        "#join tra df e reduced_df in modo da aggiungere a ogni (tutti) calciatore la sua posizione \"preferita\" e allo stesso tempo elimino le istanze dove pos == 'Sub' \n",
        "#ma non era possibile stabilire la posizione perchè non compariva mai per quel calciatore oppure a causa di una moda non unica\n",
        "df_merged = pd.merge(df,df_reduced, on = 'player')\n",
        "\n",
        "#riempio i NaN in 'pos' con la posizione di quel calciatore\n",
        "df_merged.loc[df_merged.pos_role == 'Sub','pos'] = df_merged.moda_pos\n",
        "\n",
        "#creo una colonna \"starter\", utilizzando l'informazione di pos_role. Starter=1 significa che è partito titolare, 0 se subentrato\n",
        "fill_starter = lambda x: 0 if x == 'Sub' else 1\n",
        "df_merged['starter'] = df_merged.pos_role.apply(fill_starter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "6b28c944"
      },
      "outputs": [],
      "source": [
        "#cambio l'ordine dei rating tedeschi in modo che vadano in ordine crescente da 1 a 6: 6 best performance\n",
        "df_merged.loc[((df_merged.rater == 'Kicker')|(df_merged.rater == 'Bild') ) & (df_merged.original_rating == 1), 'original_rating'] = 'a'\n",
        "df_merged.loc[(df_merged.rater == 'Kicker') & (df_merged.original_rating == 1.5), 'original_rating'] = 'b'\n",
        "df_merged.loc[((df_merged.rater == 'Kicker')|(df_merged.rater == 'Bild') ) & (df_merged.original_rating == 2), 'original_rating'] = 'c'\n",
        "df_merged.loc[(df_merged.rater == 'Kicker') & (df_merged.original_rating == 2.5), 'original_rating'] = 'd'\n",
        "df_merged.loc[((df_merged.rater == 'Kicker')|(df_merged.rater == 'Bild') ) & (df_merged.original_rating == 3), 'original_rating'] = 'e'\n",
        "df_merged.loc[((df_merged.rater == 'Kicker')|(df_merged.rater == 'Bild') ) & (df_merged.original_rating == 4), 'original_rating'] = 'f'\n",
        "df_merged.loc[(df_merged.rater == 'Kicker') & (df_merged.original_rating == 4.5), 'original_rating'] = 'g'\n",
        "df_merged.loc[((df_merged.rater == 'Kicker')|(df_merged.rater == 'Bild') ) & (df_merged.original_rating == 5), 'original_rating'] = 'h'\n",
        "df_merged.loc[(df_merged.rater == 'Kicker') & (df_merged.original_rating == 5.5), 'original_rating'] = 'i'\n",
        "df_merged.loc[((df_merged.rater == 'Kicker')|(df_merged.rater == 'Bild') ) & (df_merged.original_rating == 6), 'original_rating'] = 'l'\n",
        "\n",
        "\n",
        "df_merged.loc[df_merged.original_rating == 'a', 'original_rating'] = 6\n",
        "df_merged.loc[df_merged.original_rating == 'b', 'original_rating'] = 5.5\n",
        "df_merged.loc[df_merged.original_rating == 'c', 'original_rating'] = 5\n",
        "df_merged.loc[df_merged.original_rating == 'd', 'original_rating'] = 4.5\n",
        "df_merged.loc[df_merged.original_rating == 'e', 'original_rating'] = 4\n",
        "df_merged.loc[df_merged.original_rating == 'f', 'original_rating'] = 3\n",
        "df_merged.loc[df_merged.original_rating == 'g', 'original_rating'] = 2.5\n",
        "df_merged.loc[df_merged.original_rating == 'h', 'original_rating'] = 2\n",
        "df_merged.loc[df_merged.original_rating == 'i', 'original_rating'] = 1.5\n",
        "df_merged.loc[df_merged.original_rating == 'l', 'original_rating'] = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wBOYzBy6EL0z"
      },
      "outputs": [],
      "source": [
        "df_merged = df_merged.assign(rating=pd.Series(np.random.randn(49700)).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "U70pvZoZCXkb"
      },
      "outputs": [],
      "source": [
        "#Kicker\n",
        "df_merged.loc[(df_merged.original_rating <= 2) & (df_merged.rater == 'Kicker'),'rating'] = 1\n",
        "df_merged.loc[(df_merged.original_rating > 2) & (df_merged.original_rating <= 3) & (df_merged.rater == 'Kicker'),'rating'] = 2\n",
        "df_merged.loc[(df_merged.original_rating > 3) & (df_merged.original_rating <= 4) & (df_merged.rater == 'Kicker'),'rating'] = 3\n",
        "df_merged.loc[(df_merged.original_rating > 4) & (df_merged.original_rating <= 5) & (df_merged.rater == 'Kicker'),'rating'] = 4\n",
        "df_merged.loc[(df_merged.original_rating > 5) & (df_merged.rater == 'Kicker'),'rating'] = 5\n",
        "\n",
        "#Bild resta uguale\n",
        "#df_merged.loc[df_merged.rater == 'Bild','rating'] = df_merged.original_rating\n",
        "\n",
        "df_merged.loc[(df_merged.original_rating <= 2) & (df_merged.rater == 'Bild'),'rating'] = 1\n",
        "df_merged.loc[(df_merged.original_rating > 2) & (df_merged.original_rating <=3) & (df_merged.rater == 'Bild'),'rating'] = 2\n",
        "df_merged.loc[(df_merged.original_rating > 3) & (df_merged.original_rating <= 4) & (df_merged.rater == 'Bild'),'rating'] = 3\n",
        "df_merged.loc[(df_merged.original_rating > 4) & (df_merged.original_rating <=5) & (df_merged.rater == 'Bild'),'rating'] = 4\n",
        "df_merged.loc[(df_merged.original_rating > 5) & (df_merged.rater == 'Bild'),'rating'] = 5\n",
        "\n",
        "#SKYSPORTS e THEGUARDIAN\n",
        "df_merged.loc[(df_merged.original_rating <= 4) & ((df_merged.rater == 'SkySports') | (df_merged.rater == 'TheGuardian')),'rating'] = 1\n",
        "df_merged.loc[(df_merged.original_rating == 5) & ((df_merged.rater == 'SkySports') | (df_merged.rater == 'TheGuardian')),'rating'] = 2\n",
        "df_merged.loc[(df_merged.original_rating == 6) & ((df_merged.rater == 'SkySports') | (df_merged.rater == 'TheGuardian')),'rating'] = 3\n",
        "df_merged.loc[(df_merged.original_rating == 7) & ((df_merged.rater == 'SkySports') | (df_merged.rater == 'TheGuardian')),'rating'] = 4\n",
        "df_merged.loc[(df_merged.original_rating >= 8) & ((df_merged.rater == 'SkySports') | (df_merged.rater == 'TheGuardian')),'rating'] = 5\n",
        "\n",
        "#WHOSCORED E SOFASCORE\n",
        "df_merged.loc[(df_merged.original_rating < 5.5) & ((df_merged.rater == 'WhoScored') | (df_merged.rater == 'SofaScore')),'rating'] = 1\n",
        "df_merged.loc[((df_merged.original_rating >= 5.5) & (df_merged.original_rating < 6.8)) & ((df_merged.rater == 'WhoScored') | (df_merged.rater == 'SofaScore')),'rating'] = 2\n",
        "df_merged.loc[((df_merged.original_rating >= 6.8) & (df_merged.original_rating < 7.8)) & ((df_merged.rater == 'WhoScored') | (df_merged.rater == 'SofaScore')),'rating'] = 3\n",
        "df_merged.loc[((df_merged.original_rating >= 7.8) & (df_merged.original_rating < 8.8)) & ((df_merged.rater == 'WhoScored') | (df_merged.rater == 'SofaScore')),'rating'] = 4\n",
        "df_merged.loc[(df_merged.original_rating >= 8.8) & ((df_merged.rater == 'WhoScored') | (df_merged.rater == 'SofaScore')),'rating'] = 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AuXDAdtCXmk",
        "outputId": "3f5d195b-86b1-4f9e-e7f5-7e2fba1866c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0    19345\n",
              "2.0    18587\n",
              "4.0     7502\n",
              "1.0     2633\n",
              "5.0     1632\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df_merged.drop([13438], axis=0, inplace=True)\n",
        "\n",
        "df_merged.rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "68o1oPWnDMin"
      },
      "outputs": [],
      "source": [
        "#unisco i dataframe in uno\n",
        "df_def = df_merged\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYqDKnTkIWDk",
        "outputId": "96c3ed91-9bb2-4936-ca9a-56b1467fe2c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0    19345\n",
              "2.0    18587\n",
              "4.0     7502\n",
              "1.0     2633\n",
              "5.0     1632\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df_def.rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4dyuA1XIDMug"
      },
      "outputs": [],
      "source": [
        "df_def = df_def.drop(columns= ['rater', 'is_human','original_rating'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su0JLgw4IpKB",
        "outputId": "817b61ef-9230-4a6a-8e27-dbcf95338eae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0    13021\n",
              "2.0    12946\n",
              "4.0     5865\n",
              "1.0     2011\n",
              "5.0     1300\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "df_wod = df_def.drop_duplicates()\n",
        "df_wod.rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Y1se_XoQq3j9"
      },
      "outputs": [],
      "source": [
        "df_grouped = df_wod.groupby(['date','team','player']).filter(lambda g: len(g) > 1).groupby(['date','team','player']).size().to_frame('num_ratings')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhkpcvvctvAu",
        "outputId": "515fb80a-ddee-4fbf-e13c-b9207ee7c6b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.0    3960\n",
              "3.0    2698\n",
              "4.0     632\n",
              "5.0     165\n",
              "1.0     114\n",
              "Name: rating, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "df_merged2 = pd.merge(df_wod,df_grouped, on =['date','team','player'], how='outer')\n",
        "\n",
        "df_merged2 = df_merged2[df_merged2.num_ratings.isna()]\n",
        "\n",
        "df = df_merged2.drop(columns = ['competition','date','match','team','pos_role','player','degree_centrality','moda_pos'])\n",
        "\n",
        "df.rating.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "hMHo0yNi6H-Y"
      },
      "outputs": [],
      "source": [
        "#creo dataframes diversi per ogni ruolo, eliminando per ognuno ulteriori colonne inutili\n",
        "df_gk = df[df.pos == 'GK']\n",
        "df_gk = df_gk.drop(columns= ['pos','goals','shots_ontarget','num_ratings','shots_offtarget','shotsblocked','chances2score','drib_unsuccess'])\n",
        "\n",
        "df_def = df[df.pos == 'DF']\n",
        "df_def = df_def.drop(columns= ['pos','goals_ag_otb','goals_ag_itb','saves_itb','saves_otb','saved_pen','num_ratings'])\n",
        "\n",
        "df_dmf = df[df.pos == 'DMF']\n",
        "df_dmf = df_dmf.drop(columns= ['pos','goals_ag_otb','goals_ag_itb','saves_itb','saves_otb','saved_pen','num_ratings'])\n",
        "\n",
        "df_mf = df[df.pos == 'MF']\n",
        "df_mf = df_mf.drop(columns= ['pos','goals_ag_otb','goals_ag_itb','saves_itb','saves_otb','saved_pen','num_ratings'])\n",
        "\n",
        "df_amf = df[df.pos == 'AMF']\n",
        "df_amf = df_amf.drop(columns= ['pos','goals_ag_otb','goals_ag_itb','saves_itb','saves_otb','saved_pen','num_ratings'])\n",
        "\n",
        "df_fw = df[df.pos == 'FW']\n",
        "df_fw = df_fw.drop(columns= ['pos','goals_ag_otb','goals_ag_itb','saves_itb','saves_otb','saved_pen','num_ratings'])\n",
        "\n",
        "#un df per i giocatori di movimento (se serve)\n",
        "df_mov = df[df.pos != 'GK']\n",
        "df_mov = df_mov.drop(columns= ['goals_ag_otb','goals_ag_itb','saves_itb','saves_otb','saved_pen','num_ratings'])\n",
        "#uso il onehot per convertire gestire pos che è un attributo categorico e deve essere portato in numeri in qualche modo\n",
        "df_mov_onehot = pd.get_dummies(df_mov, columns=['pos'], prefix = ['pos'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TahJ8AklYgVu"
      },
      "outputs": [],
      "source": [
        "#Quello giusto\n",
        "X = df_mov_onehot.loc[:,df_mov_onehot.columns != 'rating']\n",
        "y = df_mov_onehot.iloc[:,48]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import clone\n",
        "\n",
        "\n",
        "class OrdinalClassifier():\n",
        "    \n",
        "    def __init__(self, clf):\n",
        "        self.clf = clf\n",
        "        self.clfs = {}\n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        self.unique_class = np.sort(np.unique(y))\n",
        "        if self.unique_class.shape[0] > 2:\n",
        "            for i in range(self.unique_class.shape[0]-1):\n",
        "                # for each k - 1 ordinal value we fit a binary classification problem\n",
        "                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n",
        "                clf = clone(self.clf)\n",
        "                clf.fit(X, binary_y)\n",
        "                self.clfs[i] = clf\n",
        "    \n",
        "    def predict_proba(self, X):\n",
        "        clfs_predict = {k:self.clfs[k].predict_proba(X) for k in self.clfs}\n",
        "        predicted = []\n",
        "        for i,y in enumerate(self.unique_class):\n",
        "            if i == 0:\n",
        "                # V1 = 1 - Pr(y > V1)\n",
        "                predicted.append(1 - clfs_predict[y-1][:,1])\n",
        "            elif y in clfs_predict:\n",
        "                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n",
        "                 predicted.append(clfs_predict[y-2][:,1] - clfs_predict[y-1][:,1])\n",
        "            else:\n",
        "                # Vk = Pr(y > Vk-1)\n",
        "                predicted.append(clfs_predict[y-2][:,1])\n",
        "        return np.vstack(predicted).T\n",
        "    \n",
        "    def predict(self, X):\n",
        "        return np.argmax(self.predict_proba(X), axis=1) + 1"
      ],
      "metadata": {
        "id": "lDIUqJDUeSLC"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Esegui prima"
      ],
      "metadata": {
        "id": "rjg0kaHWgs2_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNxdXCTwvF2W"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Pmq2i3eA1a2"
      },
      "outputs": [],
      "source": [
        "#GOALKEEPERS\n",
        "df_gk.loc[df_gk.rating==2,'rating'] = 1\n",
        "df_gk.loc[df_gk.rating==4,'rating'] = 5\n",
        "\n",
        "df_gk.loc[df_gk.rating==3,'rating'] = 2\n",
        "df_gk.loc[df_gk.rating==5,'rating'] = 3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df_gk.iloc[:,:47]\n",
        "y = df_gk.iloc[:,47]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.3, stratify=y)"
      ],
      "metadata": {
        "id": "t658QUXp2Xoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "tdykuY9rT5OX"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.multiclass import type_of_target\n",
        "type_of_target(X_train)\n",
        "y_test = y_test.astype(int)\n",
        "y_train = y_train.astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UJJRlBdCep77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3VuGOzjrLN_",
        "outputId": "5e7f5081-a588-4f0f-af14-01ac25e86aba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unique_class è: 5\n",
            "Time to build the model: 0.0920419692993164\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from datetime import time, datetime, date\n",
        "import time\n",
        "pipe = Pipeline([\n",
        "         #('normalization',StandardScaler()),        \n",
        "         #('feature_sel',SelectFromModel(RandomForestClassifier(max_features=16, min_samples_split=3))),\n",
        "         #('feature_sel',SelectKBest(score_func=f_classif, k=28)),\n",
        "         #('feature_sel',PCA(n_components= 0.95)),\n",
        "         #('sampling', RandomOverSampler()),\n",
        "         #('sampling', SMOTE()),\n",
        "         #('feature_sel',RFE(estimator=XGBClassifier(), n_features_to_select=30))\n",
        "         #('classification', XGBClassifier(max_depth=5, min_child_weight=3,colsample_bytree=0.9,subsample=0.8))\n",
        "         #('classification', KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1))\n",
        "         #('classification', LogisticRegression(C=100,solver='newton-cg'))\n",
        "         #('classification', svm.SVC(kernel= 'linear',C=0.75,gamma='auto'))\n",
        "         #('classification', XGBClassifier())\n",
        "         #('classification', RandomForestClassifier(max_features=16, min_samples_split=3))        \n",
        "         #('classification', LogisticRegression())\n",
        "         #('classification', KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1,weights=\"distance\"))\n",
        "         #('classification', BernoulliNB())\n",
        "         #('classification', svm.SVC(kernel= 'linear',C=0.75,gamma='auto'))\n",
        "         #('classification',BaggingClassifier(base_estimator=svm.SVC(kernel= 'linear',C=0.75,gamma='auto',probability=False),n_jobs=-1))\n",
        "         #('classification', AdaBoostClassifier(base_estimator=svm.SVC(kernel= 'linear',C=0.7,gamma='auto')))\n",
        "         #('classification', LogisticRegression(solver='newton-cg'))\n",
        "         ('classification', OrdinalClassifier(DecisionTreeClassifier(max_depth=3)))\n",
        "    ])\n",
        "t1 = time.time()\n",
        "pipe.fit(X_train,y_train)\n",
        "t2 = time.time()\n",
        "print(f\"Time to build the model: {t2 - t1}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#PROVA A PREDIRNE 1\n",
        "\n",
        "#feature selection\n",
        "X_train.drop(['shots_offtarget','shotsblocked','drib_unsuccess','keypasses','crosses_acc','crosses_inacc','grduels_l','aerials_l','fouls','wasfouled','stop_shots','dribbled_past','tballs_acc','tballs_inacc','ycards','dangmistakes','offsides','missed_penalties','owngoals','is_home_team','game_duration','pos_AMF','pos_DMF','pos_FW','pos_MF'],inplace=True, axis=1)"
      ],
      "metadata": {
        "id": "c6FQldVWYlCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eseguire la cella 47 per allenare il modello con le features selezionate"
      ],
      "metadata": {
        "id": "OinLoBKPiIpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uno = [[3,0,0,0,0,34,20,5,5,1,0,2,11,8,3,0,0,2,0.143055419,0.603571429,0.304347826,0,0,0,1,90,1,0]]\n",
        "result = pipe.predict(uno)\n",
        "print(f\"The rating is {result}\")"
      ],
      "metadata": {
        "id": "XFUM7T3Ph_oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SAVE THE MODEL\n",
        "import pickle\n",
        "\n",
        "filename = 'model_mov.sav'\n",
        "pickle.dump(pipe, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "Gc0E26UsiUv_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LOAD THE MODEL\n",
        "loaded_model = pickle.load(open('model_mov.sav', 'rb'))"
      ],
      "metadata": {
        "id": "KfQu-lMLuIpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "Lwmg4YTxrNYq",
        "outputId": "83f8ade0-c173-44f2-a2ed-d6711764254d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction time: 0.019222259521484375\n",
            "0.76269621421976\n",
            "0.2573635101317005\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1      0.857     0.222     0.353        27\n",
            "           2      0.828     0.865     0.846      1159\n",
            "           3      0.700     0.684     0.692       752\n",
            "           4      0.568     0.578     0.573       180\n",
            "           5      0.812     0.542     0.650        48\n",
            "\n",
            "    accuracy                          0.763      2166\n",
            "   macro avg      0.753     0.578     0.623      2166\n",
            "weighted avg      0.762     0.763     0.759      2166\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "t1 = time.time()\n",
        "y_pred = pipe.predict(X_test)\n",
        "t2 = time.time()\n",
        "print(f\"Prediction time: {t2 - t1}\")\n",
        "\n",
        "print(accuracy_score(y_pred,y_test))\n",
        "print(macro_averaged_mean_absolute_error(y_pred,y_test))\n",
        "print(classification_report(y_test,y_pred,digits = 3))\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred)\n",
        "plt.show()\n",
        "\n",
        "#calcola tutti gli alberi e li stampa in un file chiamato out.txt\n",
        "#pipe['classification'].get_booster().dump_model(\"out.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "MblHlOjEqEJI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e459aafb-8d26-454a-a92c-b7775984c58d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['fit_time', 'score_time', 'estimator', 'test_acc', 'train_acc', 'test_prec_macro', 'train_prec_macro', 'test_prec_weighted', 'train_prec_weighted', 'test_rec_macro', 'train_rec_macro', 'test_rec_weighted', 'train_rec_weighted', 'test_f1_macro', 'train_f1_macro', 'test_f1_weighted', 'train_f1_weighted', 'test_mae', 'train_mae', 'test_rmse', 'train_rmse', 'test_mamae', 'train_mamae', 'test_balacc', 'train_balacc'])\n",
            "Accuracy in each fold: [nan nan nan nan nan nan nan nan nan nan]\n",
            "Average Accuracy: nan\n",
            "Precision macro: nan\n",
            "Recall macro: nan\n",
            "F1 score macro: nan\n",
            "Mean Absolute Error: nan\n",
            "Root Mean Squared Error: nan\n",
            "Macro averaged mean absolute error: nan\n",
            "Macro averaged mean absolute error: [nan nan nan nan nan nan nan nan nan nan]\n",
            "Balanced accuracy: nan\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "10 fits failed out of a total of 10.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8e5cf3d0>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8e03f550>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8e10aa10>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8e1eae10>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8de8e710>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8de8ef90>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8de8e750>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8de8e5d0>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8e1d9650>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "1 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 262, in fit\n",
            "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/imblearn/pipeline.py\", line 217, in _fit\n",
            "    **fit_params_steps[name],\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/joblib/memory.py\", line 349, in __call__\n",
            "    return self.func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/pipeline.py\", line 893, in _fit_transform_one\n",
            "    res = transformer.fit_transform(X, y, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 855, in fit_transform\n",
            "    return self.fit(X, y, **fit_params).transform(X)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/feature_selection/_from_model.py\", line 266, in fit\n",
            "    self.estimator_ = clone(self.estimator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/base.py\", line 80, in clone\n",
            "    \"'get_params' method.\" % (repr(estimator), type(estimator))\n",
            "TypeError: Cannot clone object '<__main__.OrdinalClassifier object at 0x7f6c8e1d9bd0>' (type <class '__main__.OrdinalClassifier'>): it does not seem to be a scikit-learn estimator as it does not implement a 'get_params' method.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for i in range(10):\\n  print(\"Selected features\")\\n  filter = scores[\\'estimator\\'][i][\\'feature_sel\\'].get_support()\\n  features = np.array(X.columns)\\n  print(f\"Fold {i}: {features[filter]}\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "#CROSS VALIDATION\n",
        "pipe = Pipeline([\n",
        "         \n",
        "         #('normalization',StandardScaler()),\n",
        "         #('feature_sel',SelectKBest(score_func=f_classif, k=28)),\n",
        "         #('feature_sel',SelectFromModel(OrdinalClassifier(DecisionTreeClassifier(max_depth=3)))),\n",
        "         #('feature_sel',VarianceThreshold(threshold= 0.1)),\n",
        "         #('feature_sel',RFECV(estimator=XGBClassifier())),\n",
        "         #('feature_sel', ExtraTreesClassifier(n_estimators=10)), \n",
        "         #SequentialFeatureSelector(estimator=XGBClassifier(), n_features_to_select = 15, cv =10, direction ='backward'),\n",
        "  \n",
        "         #('sampling', SMOTE()),\n",
        "         #('sampling', RandomOverSampler()),\n",
        "         #('feature_sel',RFE(estimator=XGBClassifier(), n_features_to_select=30)),\n",
        "         #('classification', LogisticRegression(C=100,solver='newton-cg'))\n",
        "         #('classification',RandomForestClassifier(max_features=17, min_samples_split=3, max_depth=90))\n",
        "         \n",
        "         #('classification',RandomForestClassifier( max_features=17,  min_samples_split=3))\n",
        "         #('classification', KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1,weights=\"distance\"))\n",
        "         #('classification', XGBClassifier(max_depth=5, min_child_weight=3,colsample_bytree=0.9,subsample=0.8))\n",
        "         #('classification', BernoulliNB()), \n",
        "         #('classification', LogisticRegression(solver='newton-cg'))\n",
        "         #('classification', svm.SVC())\n",
        "         #('classification', svm.SVC(kernel= 'linear',C=0.7,gamma='auto'))\n",
        "         #('classification',BaggingClassifier(base_estimator=svm.SVC(kernel= 'linear',C=0.75,gamma='auto',probability=False),n_jobs=-1))\n",
        "         #('classification', OrdinalClassifier(DecisionTreeClassifier(max_depth=3))),\n",
        "         ('classification', OrdinalClassifier(DecisionTreeClassifier(max_depth=3)))\n",
        "         #('classification', DecisionTreeClassifier())\n",
        "         #('classification', DecisionTreeClassifier(max_depth=2, criterion='gini', min_samples_leaf=20))\n",
        "\n",
        "    ])\n",
        "\n",
        "mamae_scorer = make_scorer(macro_averaged_mean_absolute_error, greater_is_better=True)\n",
        "balacc_scorer = make_scorer(balanced_accuracy_score, greater_is_better=True)\n",
        "\n",
        "scoring = {'acc': 'accuracy',\n",
        "           'prec_macro': 'precision_macro',\n",
        "           'prec_weighted': 'precision_weighted',\n",
        "           'rec_macro': 'recall_macro',\n",
        "           'rec_weighted': 'recall_weighted',\n",
        "           'f1_macro': 'f1_macro',\n",
        "           'f1_weighted': 'f1_weighted',\n",
        "           'mae': 'neg_mean_absolute_error',\n",
        "           'rmse': 'neg_root_mean_squared_error',\n",
        "           'mamae': mamae_scorer,\n",
        "           'balacc': balacc_scorer}\n",
        "\n",
        "scores = cross_validate(pipe, X, y, scoring=scoring, cv=StratifiedKFold(10), return_train_score=True, return_estimator = True)\n",
        "print(scores.keys())\n",
        "print(f\"Accuracy in each fold: {scores['test_acc']}\")\n",
        "print(f\"Average Accuracy: {scores['test_acc'].mean().round(3)}\")\n",
        "print(f\"Precision macro: {scores['test_prec_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg Precision: {scores['test_prec_weighted'].mean().round(3)}\")\n",
        "print(f\"Recall macro: {scores['test_rec_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg recall: {scores['test_rec_weighted'].mean().round(3)}\")\n",
        "print(f\"F1 score macro: {scores['test_f1_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg F1: {scores['test_f1_weighted'].mean().round(3)}\")\n",
        "print(f\"Mean Absolute Error: {scores['test_mae'].mean().round(3)}\")\n",
        "print(f\"Root Mean Squared Error: {scores['test_rmse'].mean().round(3)}\")\n",
        "print(f\"Macro averaged mean absolute error: {scores['test_mamae'].mean().round(3)}\")\n",
        "print(f\"Macro averaged mean absolute error: {scores['test_mamae']}\")\n",
        "print(f\"Balanced accuracy: {scores['test_balacc'].mean().round(3)}\")\n",
        "\n",
        "\"\"\"for i in range(10):\n",
        "  print(\"Selected features\")\n",
        "  filter = scores['estimator'][i]['feature_sel'].get_support()\n",
        "  features = np.array(X.columns)\n",
        "  print(f\"Fold {i}: {features[filter]}\")\"\"\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Z_CsCGXVz_Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Weka cfs+SubSetEval"
      ],
      "metadata": {
        "id": "iSEUuM3YUaOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install javabridge\n",
        "\n",
        "!pip install python-weka-wrapper3\n",
        "\n",
        "import weka.core.jvm as jvm\n",
        "jvm.start()"
      ],
      "metadata": {
        "id": "3GtD7Le0d_Nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62bc6b6b-bf3d-4bb5-fb7d-066302ebf497"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting javabridge\n",
            "  Downloading javabridge-1.0.19.tar.gz (1.3 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 23.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 61 kB 26.3 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 71 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 81 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 92 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 102 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 112 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███                             | 122 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 133 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 143 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 153 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 163 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 174 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 184 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 194 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 204 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████                           | 215 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 225 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 235 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 245 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 256 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 266 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 276 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 286 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████                         | 296 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 307 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 317 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 327 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████                        | 337 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 348 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 358 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 368 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 378 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 389 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 399 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 409 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 419 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 430 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 440 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 450 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 460 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 471 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 481 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 491 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 501 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 512 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 522 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 532 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 542 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 552 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 563 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 573 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 583 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 593 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 604 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 614 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 624 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 634 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 645 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 655 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 665 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 675 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 686 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 696 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 706 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 716 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 727 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 737 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 747 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 757 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 768 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 778 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 788 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 798 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 808 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 819 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 829 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 839 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 849 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 860 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 870 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 880 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 890 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 901 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 911 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 921 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 931 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 942 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 952 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 962 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 972 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 983 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 993 kB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.0 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.0 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.0 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.0 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.0 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.1 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.2 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.3 MB 27.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.3 MB 27.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from javabridge) (1.21.5)\n",
            "Building wheels for collected packages: javabridge\n",
            "  Building wheel for javabridge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for javabridge: filename=javabridge-1.0.19-cp37-cp37m-linux_x86_64.whl size=1636714 sha256=0006b9b55c529cc1291b3374ae86e799e437af8cd15ea2cac1c4fabbe28550c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/5e/7f/e1dd610613dcde4a4ed2974b4208ba90247a2dfc9add216c59\n",
            "Successfully built javabridge\n",
            "Installing collected packages: javabridge\n",
            "Successfully installed javabridge-1.0.19\n",
            "Collecting python-weka-wrapper3\n",
            "  Downloading python-weka-wrapper3-0.2.7.tar.gz (14.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.4 MB 17.1 MB/s \n",
            "\u001b[?25hCollecting python-javabridge>=4.0.0\n",
            "  Downloading python-javabridge-4.0.3.tar.gz (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from python-weka-wrapper3) (1.21.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from python-weka-wrapper3) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->python-weka-wrapper3) (3.0.7)\n",
            "Building wheels for collected packages: python-weka-wrapper3, python-javabridge\n",
            "  Building wheel for python-weka-wrapper3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-weka-wrapper3: filename=python_weka_wrapper3-0.2.7-py3-none-any.whl size=12989631 sha256=20a5aa79314bd12c1f8d2ade9236f521634a0cb3d0f2d72819f6d680c1258b96\n",
            "  Stored in directory: /root/.cache/pip/wheels/72/3a/e8/c7599e834e6c9610a3be9ecb0c158eab1b7548025e4d24b3c3\n",
            "  Building wheel for python-javabridge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-javabridge: filename=python_javabridge-4.0.3-cp37-cp37m-linux_x86_64.whl size=1628171 sha256=894d64d368253dbf818d8ecd940a5ed386263ccf7111860a57c36f8ebf550623\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/7e/91/01b1bd8d29b4323834feb5cfec49b857fb212e6efc74ce103c\n",
            "Successfully built python-weka-wrapper3 python-javabridge\n",
            "Installing collected packages: python-javabridge, python-weka-wrapper3\n",
            "Successfully installed python-javabridge-4.0.3 python-weka-wrapper3-0.2.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG:weka.core.jvm:Adding bundled jars\n",
            "DEBUG:weka.core.jvm:Classpath=['/usr/local/lib/python3.7/dist-packages/javabridge/jars/rhino-1.7R4.jar', '/usr/local/lib/python3.7/dist-packages/javabridge/jars/runnablequeue.jar', '/usr/local/lib/python3.7/dist-packages/javabridge/jars/cpython.jar', '/usr/local/lib/python3.7/dist-packages/weka/lib/python-weka-wrapper.jar', '/usr/local/lib/python3.7/dist-packages/weka/lib/weka.jar']\n",
            "DEBUG:weka.core.jvm:MaxHeapSize=default\n",
            "DEBUG:weka.core.jvm:Package support disabled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creo i fold e li salvo in delle liste: X_train_base, X_test_base, Y_train_base, Y_test_base\n",
        "skf = StratifiedKFold(10)\n",
        "\n",
        "X_train_base=[]\n",
        "X_test_base=[]\n",
        "Y_train_base=[]\n",
        "Y_test_base=[]\n",
        "\n",
        "for train_index, test_index in skf.split(X,y):\n",
        "\n",
        "    X_train, X_test = X.iloc[train_index,:], X.iloc[test_index,:]\n",
        "    Y_train, Y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "    X_train_base.append(X_train)\n",
        "    X_test_base.append(X_test)\n",
        "    Y_train_base.append(Y_train)\n",
        "    Y_test_base.append(Y_test)\n",
        "\n",
        "#print(X_train_base[0])\n",
        "#print(Y_train_base[0])\n",
        "#print(X_train_base[1])\n",
        "#print(Y_train_base[1])"
      ],
      "metadata": {
        "id": "LQEY5-xaUkGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_base_c = X_train_base.copy()\n",
        "Y_train_base_c = Y_train_base.copy()"
      ],
      "metadata": {
        "id": "2ONeYPj8OaIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converto i df in numpy array in modo da poter essere \"letti\" da weka\n",
        "for i in range(10):  \n",
        "  X_train_base_c[i] = X_train_base_c[i].to_numpy()\n",
        "  Y_train_base_c[i] = Y_train_base_c[i].to_numpy()"
      ],
      "metadata": {
        "id": "HMq1jPxgQ8OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from weka.core.dataset import create_instances_from_matrices\n",
        "#creo fold: una lista di dataset\n",
        "fold = []\n",
        "\n",
        "for i in range(10):\n",
        "  fold.append(create_instances_from_matrices(X_train_base_c[i],Y_train_base_c[i]))"
      ],
      "metadata": {
        "id": "fODumzBeQ8Q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#settiamo la classe in tutti i fold\n",
        "for i in range(10):\n",
        "    fold[i].class_is_last()"
      ],
      "metadata": {
        "id": "UV1ucarfca5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform the attribute selection e per ogni fold elimino le features non necessarie, quindi avrò per ogni fold solo le features selezionate\n",
        "from weka.attribute_selection import ASSearch, ASEvaluation, AttributeSelection\n",
        "search = ASSearch(classname=\"weka.attributeSelection.BestFirst\", options=[\"-D\", \"1\", \"-N\", \"\"])\n",
        "evaluator = ASEvaluation(classname=\"weka.attributeSelection.CfsSubsetEval\", options=[\"-P\", \"1\", \"-E\", \"1\"])\n",
        "attsel = AttributeSelection()\n",
        "attsel.search(search)\n",
        "attsel.evaluator(evaluator)\n",
        "\n",
        "for i in range(10):\n",
        "  attsel.select_attributes(fold[i])\n",
        "  print(\"# attributes: \" + str(attsel.number_attributes_selected))\n",
        "  print(\"attributes: \" + str(attsel.selected_attributes))\n",
        "  selected_attributes = np.delete(attsel.selected_attributes, attsel.selected_attributes.size-1)\n",
        "  X_train_base[i]= X_train_base[i].iloc[:,selected_attributes]\n",
        "  X_test_base[i]= X_test_base[i].iloc[:,selected_attributes]\n",
        "#print(\"result string:\\n\" + attsel.results_string)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7DCd69oUVKE",
        "outputId": "8118269c-0dce-46dd-a511-618e4bfaed04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# attributes: 14\n",
            "attributes: [ 0 10 12 13 21 26 29 30 31 32 33 36 38 42 47]\n",
            "# attributes: 13\n",
            "attributes: [10 13 16 26 29 30 31 32 33 36 38 40 42 47]\n",
            "# attributes: 15\n",
            "attributes: [ 0 10 11 12 13 26 29 30 31 32 33 36 38 41 42 47]\n",
            "# attributes: 15\n",
            "attributes: [ 0  2 10 12 13 26 29 30 31 32 33 36 38 41 42 47]\n",
            "# attributes: 14\n",
            "attributes: [ 0 10 11 12 13 26 29 30 31 32 33 36 38 42 47]\n",
            "# attributes: 13\n",
            "attributes: [ 0 10 13 16 17 26 29 30 31 32 33 36 42 47]\n",
            "# attributes: 13\n",
            "attributes: [ 0 10 12 13 26 29 30 31 32 33 36 38 42 47]\n",
            "# attributes: 13\n",
            "attributes: [ 0 10 12 13 26 29 30 31 32 33 36 38 42 47]\n",
            "# attributes: 13\n",
            "attributes: [ 0 10 11 12 13 26 29 30 31 32 33 36 42 47]\n",
            "# attributes: 12\n",
            "attributes: [ 0 10 13 26 29 30 31 32 33 36 38 42 47]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "model = svm.SVC(kernel= 'linear',C=0.7,gamma='auto')\n",
        "\n",
        "model.fit(X_train_base[7],Y_train_base[7])\n",
        "\n",
        "filename = 'model_gk2.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "CX8XjYoyYisd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eseguo la classificazione per ogni fold\n",
        "from sklearn.metrics import precision_score, f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from datetime import time, datetime, date\n",
        "import time\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1s = []\n",
        "maes = []\n",
        "rmse = []\n",
        "build_times = []\n",
        "pred_times = []\n",
        "mamae = []\n",
        "\n",
        "#model = KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1,weights=\"distance\")\n",
        "#model = XGBClassifier(max_depth=5, min_child_weight=3,colsample_bytree=0.9,subsample=0.8)\n",
        "#model = RandomForestClassifier(min_samples_split=3)\n",
        "#model = BernoulliNB()\n",
        "model = svm.SVC(kernel= 'linear',C=0.7,gamma='auto')\n",
        "\n",
        "for i in range(10):\n",
        "  t1 = time.time()\n",
        "  model.fit(X_train_base[i],Y_train_base[i])\n",
        "  #model.fit(X_train_base_resampled[i],Y_train_base_resampled[i])\n",
        "  t2 = time.time()\n",
        "  build_times.append(t2-t1)\n",
        "\n",
        "  t3 = time.time()\n",
        "  y_pred = model.predict(X_test_base[i])\n",
        "  t4 = time.time()\n",
        "  pred_times.append(t4-t3)\n",
        "\n",
        "  accuracies.append(accuracy_score(y_pred,Y_test_base[i]))\n",
        "  precisions.append(precision_score(y_pred,Y_test_base[i],average='macro'))\n",
        "  recalls.append(recall_score(y_pred,Y_test_base[i],average='macro'))\n",
        "  f1s.append(f1_score(y_pred,Y_test_base[i],average='macro'))\n",
        "  maes.append(mean_absolute_error(y_pred,Y_test_base[i]))\n",
        "  rmse.append(mean_squared_error(y_pred,Y_test_base[i],squared=False))\n",
        "  mamae.append(macro_averaged_mean_absolute_error(y_pred,Y_test_base[i]))\n",
        "  print(accuracies[i])\n",
        "  #print(accuracy_score(y_pred,Y_test_base[i]))\n",
        "  #print(classification_report(Y_test_base[i],y_pred,digits = 3))\n",
        "\n",
        "print(f\"Average accuracy: {np.mean(accuracies).round(3)}\")\n",
        "print(f\"Average precision: {np.mean(precisions).round(3)}\")\n",
        "print(f\"Average recall: {np.mean(recalls).round(3)}\")\n",
        "print(f\"Average f score: {np.mean(f1s).round(3)}\")\n",
        "print(f\"Average mean absolute error: {np.mean(maes).round(3)}\")\n",
        "print(f\"Average root mean squared error: {np.mean(rmse).round(3)}\")\n",
        "print(f\"Average build time: {np.mean(build_times).round(3)}\")\n",
        "print(f\"Average prediction time: {np.mean(pred_times).round(3)}\")\n",
        "print(f\"MACRO Average mean absolute error: {np.mean(mamae).round(3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2Z_jOfcg8dJ",
        "outputId": "07cb31c9-9666-4fe4-8820-2310c42ce28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8\n",
            "0.8857142857142857\n",
            "0.7428571428571429\n",
            "0.7428571428571429\n",
            "0.8857142857142857\n",
            "0.8571428571428571\n",
            "0.9142857142857143\n",
            "0.9142857142857143\n",
            "0.8571428571428571\n",
            "0.8823529411764706\n",
            "Average accuracy: 0.848\n",
            "Average precision: 0.772\n",
            "Average recall: 0.865\n",
            "Average f score: 0.799\n",
            "Average mean absolute error: 0.152\n",
            "Average root mean squared error: 0.382\n",
            "Average build time: 0.004\n",
            "Average prediction time: 0.002\n",
            "MACRO Average mean absolute error: 0.135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SAVE THE MODEL\n",
        "import pickle\n",
        "\n",
        "filename = 'model_gk.sav'\n",
        "pickle.dump(model, open(filename, 'wb'))"
      ],
      "metadata": {
        "id": "opHegWIM-MWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eseguo la classificazione per ogni fold. LOGISTIC REGRESSION\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.metrics import precision_score, f1_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from datetime import time, datetime, date\n",
        "import time\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1s = []\n",
        "maes = []\n",
        "rmse = []\n",
        "build_times = []\n",
        "pred_times = []\n",
        "\n",
        "#model = KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1,weights=\"distance\")\n",
        "#model = XGBClassifier(max_depth=5, min_child_weight=3,colsample_bytree=0.9,subsample=0.8)\n",
        "#model = RandomForestClassifier(max_features=13, min_samples_split=3)\n",
        "#model = BernoulliNB()\n",
        "model = Pipeline([\n",
        "                  ('normalization',StandardScaler()),\n",
        "                  ('classification', LogisticRegression(solver='newton-cg'))\n",
        "])\n",
        "\n",
        "for i in range(10):\n",
        "  t1 = time.time()\n",
        "  #model.fit(X_train_base[i],Y_train_base[i])\n",
        "  model.fit(X_train_base_resampled[i],Y_train_base_resampled[i])\n",
        "  t2 = time.time()\n",
        "  build_times.append(t2-t1)\n",
        "\n",
        "  t3 = time.time()\n",
        "  y_pred = model.predict(X_test_base[i])\n",
        "  t4 = time.time()\n",
        "  pred_times.append(t4-t3)\n",
        "\n",
        "  accuracies.append(accuracy_score(y_pred,Y_test_base[i]))\n",
        "  precisions.append(precision_score(y_pred,Y_test_base[i],average='macro'))\n",
        "  recalls.append(recall_score(y_pred,Y_test_base[i],average='macro'))\n",
        "  f1s.append(f1_score(y_pred,Y_test_base[i],average='macro'))\n",
        "  maes.append(mean_absolute_error(y_pred,Y_test_base[i]))\n",
        "  rmse.append(mean_squared_error(y_pred,Y_test_base[i],squared=False))\n",
        "  mamae.append(macro_averaged_mean_absolute_error(y_pred,Y_test_base[i]))\n",
        "  print(accuracies[i])\n",
        "  #print(accuracy_score(y_pred,Y_test_base[i]))\n",
        "  #print(classification_report(Y_test_base[i],y_pred,digits = 3))\n",
        "\n",
        "print(f\"Average accuracy: {np.mean(accuracies).round(3)}\")\n",
        "print(f\"Average precision: {np.mean(precisions).round(3)}\")\n",
        "print(f\"Average recall: {np.mean(recalls).round(3)}\")\n",
        "print(f\"Average f score: {np.mean(f1s).round(3)}\")\n",
        "print(f\"Average mean absolute error: {np.mean(maes).round(3)}\")\n",
        "print(f\"Average root mean squared error: {np.mean(rmse).round(3)}\")\n",
        "print(f\"Average build time: {np.mean(build_times).round(3)}\")\n",
        "print(f\"Average prediction time: {np.mean(pred_times).round(3)}\")\n",
        "print(f\"MACRO Average mean absolute error: {np.mean(mamae).round(3)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f06b40-ac30-40be-d775-189e99e83aac",
        "id": "RMhD-s6v2W4i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8285714285714286\n",
            "0.8857142857142857\n",
            "0.8\n",
            "0.7714285714285715\n",
            "0.9428571428571428\n",
            "0.8571428571428571\n",
            "0.9142857142857143\n",
            "0.9428571428571428\n",
            "0.9142857142857143\n",
            "0.8529411764705882\n",
            "Average accuracy: 0.871\n",
            "Average precision: 0.857\n",
            "Average recall: 0.853\n",
            "Average f score: 0.848\n",
            "Average mean absolute error: 0.132\n",
            "Average root mean squared error: 0.361\n",
            "Average build time: 0.059\n",
            "Average prediction time: 0.003\n",
            "MACRO Average mean absolute error: 0.287\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "a_NFwXt3hb7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LGoMjq0Rhb9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#REBALANCING\n",
        "copiax = X_train_base[0].copy()\n",
        "copiay = Y_train_base[0].copy()\n",
        "\n",
        "X_train_base_resampled = []\n",
        "Y_train_base_resampled = []\n",
        "\n",
        "for i in range(10):\n",
        "  x_temp, y_temp = RandomOverSampler().fit_resample(X_train_base[i],Y_train_base[i])\n",
        "  X_train_base_resampled.append(x_temp)\n",
        "  Y_train_base_resampled.append(y_temp)"
      ],
      "metadata": {
        "id": "q8emlNwx4SML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hyperparameters tuning"
      ],
      "metadata": {
        "id": "eLbIjqx0kdt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VW7FDB76kjfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoFrTLNuH6gv"
      },
      "outputs": [],
      "source": [
        "#HYPERPARAMETER TUNING XGBClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = XGBClassifier(max_depth=5,min_child_weight=3,gamma=0.4)\n",
        "parameters = {\n",
        " 'max_depth':range(3,10,2),\n",
        " 'min_child_weight':range(1,6,2)\n",
        "}\n",
        "\n",
        "parameters2 = {\n",
        " 'gamma':[i/10.0 for i in range(0,5)]\n",
        "}\n",
        "\n",
        "parameters3 = {\n",
        " 'subsample':[i/10.0 for i in range(6,10)],\n",
        " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, parameters3, cv=10, scoring=\"neg_mean_absolute_error\")\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "print(\"the best parameters are \\n {}\".format(grid.best_params_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING KNN\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = KNeighborsClassifier(n_neighbors= 10)\n",
        "parameters = {\n",
        " 'leaf_size':[1,10,15,20,30,40,50],\n",
        " 'n_neighbors': [5,7,9,10,11,13,15,20,21,22],\n",
        " 'weights' : ['uniform','distance'],\n",
        " 'p':(1,2),\n",
        " 'metric' : ['minkowski','euclidean','manhattan']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, parameters, cv=10, scoring = 'neg_mean_absolute_error')\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "print(\"the best parameters are \\n {}\".format(grid.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNJEtYR1dnLo",
        "outputId": "0f72d21d-a938-4cc9-eb5a-e8cd689f6d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the best parameters are \n",
            " {'leaf_size': 1, 'metric': 'minkowski', 'n_neighbors': 21, 'p': 1, 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING RANDOM FOREST\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "parameters = {\n",
        " 'n_estimators':[100,200,300],\n",
        " 'max_depth': [80, 90, 100, 110],\n",
        " 'max_features' : ['auto', 'sqrt'],\n",
        " 'min_samples_leaf': [1,3,5],\n",
        " 'min_samples_split' : [3,5,8,10]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, parameters, cv=10, scoring = 'neg_mean_absolute_error')\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "print(\"the best parameters are \\n {}\".format(grid.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxowdSwhMNge",
        "outputId": "b2eeef93-f5b3-41d7-8599-0bf800d0d038"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the best parameters are \n",
            " {'max_depth': 90, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING LOGISTIC REGRESSION\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = LogisticRegression()\n",
        "parameters = {\n",
        " 'solver':['newton-cg', 'lbfgs', 'liblinear'],\n",
        " 'penalty': ['none', 'l1', 'l2', 'elasticnet'],\n",
        " 'C' : [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 10, 100]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, parameters, cv=10, scoring = 'neg_mean_absolute_error')\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "print(\"the best parameters are \\n {}\".format(grid.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E84sDZyb2PYY",
        "outputId": "6ae71396-d187-4dfb-b5b0-bad24eac064a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:1208: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
            "480 fits failed out of a total of 960.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 449, in _check_solver\n",
            "    % (solver, penalty)\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "80 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py\", line 459, in _check_solver\n",
            "    solver\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py:972: UserWarning: One or more of the test scores are non-finite: [-0.18065472 -0.28669902         nan         nan         nan -0.59200524\n",
            " -0.39433569 -0.39512738 -0.40561147         nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.4402395\n",
            " -0.37059719 -0.36980511 -0.37752123         nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.40541424\n",
            " -0.32033929 -0.32350292 -0.33458459         nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.30213478\n",
            " -0.24970375 -0.29303252 -0.2700861          nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.23407584\n",
            " -0.20142566 -0.2900634  -0.23526161         nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.21646617\n",
            " -0.18421242 -0.28788557 -0.21607052         nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.21231245\n",
            " -0.18144484 -0.28274019 -0.213499           nan         nan         nan\n",
            " -0.18065472 -0.28669902         nan         nan         nan -0.2121156\n",
            " -0.18104919 -0.28472078 -0.21330255         nan         nan         nan]\n",
            "  category=UserWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:1484: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
            "  \"Setting penalty='none' will ignore the C and l1_ratio parameters\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the best parameters are \n",
            " {'C': 1e-05, 'penalty': 'none', 'solver': 'newton-cg'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#HYPERPARAMETER TUNING DECISION TREE\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model = RandomForestClassifier()\n",
        "parameters = {\n",
        "\n",
        "    'max_depth': [2, 3, 5, 10, 20],\n",
        "    'min_samples_leaf': [5, 10, 20, 50, 100],\n",
        "    'criterion': [\"gini\", \"entropy\"]\n",
        "\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(model, parameters, cv=10, scoring = mamae_scorer)\n",
        "\n",
        "grid.fit(X_train,y_train)\n",
        "print(\"the best parameters are \\n {}\".format(grid.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7991e54-ba20-4bd5-eb38-c4d4958134af",
        "id": "14t90JpVZK47"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the best parameters are \n",
            " {'criterion': 'gini', 'max_depth': 2, 'min_samples_leaf': 20}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Student t-test"
      ],
      "metadata": {
        "id": "HfyUVU7StTyj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VzP34PhStfVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01e67c3e-fd05-4c09-e776-09166817593d",
        "id": "WDDHUH9DGt9K"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['fit_time', 'score_time', 'estimator', 'test_acc', 'train_acc', 'test_prec_macro', 'train_prec_macro', 'test_prec_weighted', 'train_prec_weighted', 'test_rec_macro', 'train_rec_macro', 'test_rec_weighted', 'train_rec_weighted', 'test_f1_macro', 'train_f1_macro', 'test_f1_weighted', 'train_f1_weighted', 'test_mae', 'train_mae', 'test_rmse', 'train_rmse'])\n",
            "Accuracy in each fold: [0.7867036  0.78947368 0.77977839 0.7867036  0.73822715 0.78393352\n",
            " 0.81440443 0.79224377 0.8365651  0.78808864]\n",
            "Average Accuracy: 0.79\n",
            "Precision macro: 0.691\n",
            "Recall macro: 0.563\n",
            "F1 score macro: 0.588\n",
            "Mean Absolute Error: -0.213\n",
            "Root Mean Squared Error: -0.466\n",
            "Selected features\n",
            "Fold 0: ['goals' 'assists' 'shots_ontarget' 'touches' 'passes_acc' 'passes_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 1: ['goals' 'assists' 'shots_ontarget' 'touches' 'passes_acc' 'passes_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 2: ['goals' 'shots_ontarget' 'touches' 'passes_acc' 'passes_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 3: ['goals' 'shots_ontarget' 'touches' 'passes_acc' 'passes_inacc'\n",
            " 'lballs_acc' 'grduels_w' 'aerials_w' 'poss_lost' 'clearances'\n",
            " 'betweenness_centrality' 'closeness_centrality' 'flow_centrality'\n",
            " 'flow_success' 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 4: ['goals' 'assists' 'shots_ontarget' 'touches' 'passes_acc' 'grduels_w'\n",
            " 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 5: ['goals' 'shots_ontarget' 'touches' 'passes_acc' 'passes_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 6: ['goals' 'shots_ontarget' 'touches' 'passes_acc' 'grduels_w' 'aerials_w'\n",
            " 'poss_lost' 'clearances' 'betweenness_centrality' 'closeness_centrality'\n",
            " 'flow_centrality' 'flow_success' 'betweenness2goals' 'win' 'lost'\n",
            " 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 7: ['goals' 'shots_ontarget' 'touches' 'passes_acc' 'grduels_w' 'aerials_w'\n",
            " 'poss_lost' 'clearances' 'betweenness_centrality' 'closeness_centrality'\n",
            " 'flow_centrality' 'flow_success' 'betweenness2goals' 'win' 'lost'\n",
            " 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 8: ['goals' 'assists' 'shots_ontarget' 'touches' 'passes_acc' 'lballs_acc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed']\n",
            "Selected features\n",
            "Fold 9: ['goals' 'shots_ontarget' 'touches' 'passes_acc' 'lballs_acc' 'grduels_w'\n",
            " 'aerials_w' 'poss_lost' 'clearances' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "#CROSS VALIDATION\n",
        "pipe = Pipeline([\n",
        "         \n",
        "         #('normalization',StandardScaler()),\n",
        "         #('feature_sel',SelectKBest(score_func=f_classif, k=28)),\n",
        "         ('feature_sel',SelectFromModel(RandomForestClassifier( max_features=16,  min_samples_split=3))),\n",
        "         #('sampling', SMOTE()),\n",
        "         #('sampling', RandomOverSampler()),\n",
        "         \n",
        "         ('classification',RandomForestClassifier( max_features=16,  min_samples_split=3))\n",
        "         #('classification', KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1,weights=\"distance\"))\n",
        "         #('classification', XGBClassifier(max_depth=5, min_child_weight=3,colsample_bytree=0.9,subsample=0.8))\n",
        "         #('classification', BernoulliNB()), \n",
        "         #('classification', LogisticRegression(solver='newton-cg'))\n",
        "         #('classification', svm.SVC())\n",
        "         #('classification', svm.SVC(kernel= 'linear',C=0.7,gamma='auto'))\n",
        "         #('classification',BaggingClassifier(base_estimator=svm.SVC(kernel= 'linear',C=0.75,gamma='auto',probability=False),n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "scoring = {'acc': 'accuracy',\n",
        "           'prec_macro': 'precision_macro',\n",
        "           'prec_weighted': 'precision_weighted',\n",
        "           'rec_macro': 'recall_macro',\n",
        "           'rec_weighted': 'recall_weighted',\n",
        "           'f1_macro': 'f1_macro',\n",
        "           'f1_weighted': 'f1_weighted',\n",
        "           'mae': 'neg_mean_absolute_error',\n",
        "           'rmse': 'neg_root_mean_squared_error'}\n",
        "scores = cross_validate(pipe, X, y, scoring=scoring, cv=StratifiedKFold(10), return_train_score=True, return_estimator = True)\n",
        "print(scores.keys())\n",
        "print(f\"Accuracy in each fold: {scores['test_acc']}\")\n",
        "print(f\"Average Accuracy: {scores['test_acc'].mean().round(3)}\")\n",
        "print(f\"Precision macro: {scores['test_prec_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg Precision: {scores['test_prec_weighted'].mean().round(3)}\")\n",
        "print(f\"Recall macro: {scores['test_rec_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg recall: {scores['test_rec_weighted'].mean().round(3)}\")\n",
        "print(f\"F1 score macro: {scores['test_f1_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg F1: {scores['test_f1_weighted'].mean().round(3)}\")\n",
        "print(f\"Mean Absolute Error: {scores['test_mae'].mean().round(3)}\")\n",
        "print(f\"Root Mean Squared Error: {scores['test_rmse'].mean().round(3)}\")\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Selected features\")\n",
        "  filter = scores['estimator'][i]['feature_sel'].get_support()\n",
        "  features = np.array(X.columns)\n",
        "  print(f\"Fold {i}: {features[filter]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "euP-fdSzbjnQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f8a7dfb-3083-4f45-ef85-d62fbfc970d2",
        "id": "Mt089SW4bkXF"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['fit_time', 'score_time', 'estimator', 'test_acc', 'train_acc', 'test_prec_macro', 'train_prec_macro', 'test_prec_weighted', 'train_prec_weighted', 'test_rec_macro', 'train_rec_macro', 'test_rec_weighted', 'train_rec_weighted', 'test_f1_macro', 'train_f1_macro', 'test_f1_weighted', 'train_f1_weighted', 'test_mae', 'train_mae', 'test_rmse', 'train_rmse'])\n",
            "Accuracy in each fold: [0.82409972 0.79778393 0.7867036  0.79778393 0.7867036  0.82963989\n",
            " 0.83518006 0.82825485 0.8434903  0.81855956]\n",
            "Average Accuracy: 0.815\n",
            "Precision macro: 0.807\n",
            "Recall macro: 0.633\n",
            "F1 score macro: 0.673\n",
            "Mean Absolute Error: -0.186\n",
            "Root Mean Squared Error: -0.434\n",
            "Selected features\n",
            "Fold 0: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter' 'pos_DF']\n",
            "Selected features\n",
            "Fold 1: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter' 'pos_DF']\n",
            "Selected features\n",
            "Fold 2: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'keypasses' 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc'\n",
            " 'lballs_inacc' 'grduels_w' 'aerials_w' 'poss_lost' 'clearances'\n",
            " 'interceptions' 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 3: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter' 'pos_DF']\n",
            "Selected features\n",
            "Fold 4: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'keypasses' 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc'\n",
            " 'lballs_inacc' 'grduels_w' 'aerials_w' 'poss_lost' 'clearances'\n",
            " 'interceptions' 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 5: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'tballs_acc' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n",
            "Selected features\n",
            "Fold 6: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter' 'pos_DF']\n",
            "Selected features\n",
            "Fold 7: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter' 'pos_DF']\n",
            "Selected features\n",
            "Fold 8: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter' 'pos_DF']\n",
            "Selected features\n",
            "Fold 9: ['goals' 'assists' 'shots_ontarget' 'chances2score' 'drib_success'\n",
            " 'touches' 'passes_acc' 'passes_inacc' 'lballs_acc' 'lballs_inacc'\n",
            " 'grduels_w' 'aerials_w' 'poss_lost' 'clearances' 'interceptions'\n",
            " 'tackles' 'tballs_acc' 'rcards' 'countattack' 'betweenness_centrality'\n",
            " 'closeness_centrality' 'flow_centrality' 'flow_success'\n",
            " 'betweenness2goals' 'win' 'lost' 'minutesPlayed' 'starter']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "#CROSS VALIDATION\n",
        "pipe = Pipeline([\n",
        "         \n",
        "         #('normalization',StandardScaler()),\n",
        "         ('feature_sel',SelectKBest(score_func=f_classif, k=28)),\n",
        "         #('feature_sel',SelectFromModel(RandomForestClassifier( max_features=16,  min_samples_split=3))),\n",
        "         #('sampling', SMOTE()),\n",
        "         #('sampling', RandomOverSampler()),\n",
        "         #('classification', LogisticRegression(C=100,solver='newton-cg'))\n",
        "         \n",
        "         #('classification',RandomForestClassifier( max_features=16,  min_samples_split=3))\n",
        "         #('classification', KNeighborsClassifier(n_neighbors= 21,leaf_size=1,p=1,weights=\"distance\"))\n",
        "         #('classification', XGBClassifier(max_depth=5, min_child_weight=3,colsample_bytree=0.9,subsample=0.8))\n",
        "         #('classification', BernoulliNB()), \n",
        "         #('classification', LogisticRegression(solver='newton-cg'))\n",
        "         #('classification', svm.SVC())\n",
        "         ('classification', svm.SVC(kernel= 'linear',C=0.7,gamma='auto'))\n",
        "         #('classification',BaggingClassifier(base_estimator=svm.SVC(kernel= 'linear',C=0.75,gamma='auto',probability=False),n_jobs=-1))\n",
        "    ])\n",
        "\n",
        "scoring = {'acc': 'accuracy',\n",
        "           'prec_macro': 'precision_macro',\n",
        "           'prec_weighted': 'precision_weighted',\n",
        "           'rec_macro': 'recall_macro',\n",
        "           'rec_weighted': 'recall_weighted',\n",
        "           'f1_macro': 'f1_macro',\n",
        "           'f1_weighted': 'f1_weighted',\n",
        "           'mae': 'neg_mean_absolute_error',\n",
        "           'rmse': 'neg_root_mean_squared_error'}\n",
        "scores = cross_validate(pipe, X, y, scoring=scoring, cv=StratifiedKFold(10), return_train_score=True, return_estimator = True)\n",
        "print(scores.keys())\n",
        "print(f\"Accuracy in each fold: {scores['test_acc']}\")\n",
        "print(f\"Average Accuracy: {scores['test_acc'].mean().round(3)}\")\n",
        "print(f\"Precision macro: {scores['test_prec_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg Precision: {scores['test_prec_weighted'].mean().round(3)}\")\n",
        "print(f\"Recall macro: {scores['test_rec_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg recall: {scores['test_rec_weighted'].mean().round(3)}\")\n",
        "print(f\"F1 score macro: {scores['test_f1_macro'].mean().round(3)}\")\n",
        "#print(f\"Avg F1: {scores['test_f1_weighted'].mean().round(3)}\")\n",
        "print(f\"Mean Absolute Error: {scores['test_mae'].mean().round(3)}\")\n",
        "print(f\"Root Mean Squared Error: {scores['test_rmse'].mean().round(3)}\")\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"Selected features\")\n",
        "  filter = scores['estimator'][i]['feature_sel'].get_support()\n",
        "  features = np.array(X.columns)\n",
        "  print(f\"Fold {i}: {features[filter]}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.gofplots import qqplot\n",
        "from matplotlib import pyplot\n",
        "\n",
        "qqplot(scores['test_f1_macro'],line = 's')\n",
        "pyplot.show"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "PSZcuLxnHSUU",
        "outputId": "19be9909-e4c7-4f92-8cb3-70c8ba6ddc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SHAPIRO WILK TEST\n",
        "from scipy.stats import shapiro\n",
        "\n",
        "stat, p = shapiro(scores['test_acc'])\n",
        "#stat, p = shapiro(scores['test_f1_macro'])\n",
        "#stat, p = shapiro(scores['test_mae'])\n",
        "print('Statistics=%.3f, p=%.3f' % (stat, p))\n",
        "# interpret\n",
        "alpha = 0.05\n",
        "if p > alpha:\n",
        "\tprint('Sample looks Gaussian (fail to reject H0)')\n",
        "else:\n",
        "\tprint('Sample does not look Gaussian (reject H0)')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLCHBcT1JQVv",
        "outputId": "7f6f652f-3038-4aee-bbc2-9e2594d2850f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Statistics=0.916, p=0.325\n",
            "Sample looks Gaussian (fail to reject H0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_acc = scores['test_acc']\n",
        "#if NOT Gaussian:\n",
        "a_f1 = np.sqrt(scores['test_f1_macro'])\n",
        "\n",
        "#a_f1 = scores['test_f1_macro']\n",
        "a_mae = scores['test_mae']"
      ],
      "metadata": {
        "id": "mRH1qTPfOBOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b_acc = scores['test_acc']\n",
        "b_f1 = scores['test_f1_macro']\n",
        "b_mae = scores['test_mae']"
      ],
      "metadata": {
        "id": "-z2dwi4SOVIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_rel\n",
        "\n",
        "# Python paired sample t-test\n",
        "print(f\"accuracy: {ttest_rel(a_acc, b_acc)}\")\n",
        "print(f\"f score: {ttest_rel(a_f1, b_f1)}\")\n",
        "print(f\"MAE: {ttest_rel(a_mae, b_mae)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h4UnOqYlRwI4",
        "outputId": "ef8849df-4e47-4be9-b950-0652ab7cd0e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: Ttest_relResult(statistic=1.97066740354441, pvalue=0.0802559142897024)\n",
            "f score: Ttest_relResult(statistic=18.957985878524777, pvalue=1.4547600977225277e-08)\n",
            "MAE: Ttest_relResult(statistic=1.9193450595471568, pvalue=0.08714787243447174)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "sei.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}